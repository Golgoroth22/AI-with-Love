#  День 6. Температура

## Запустите один и тот же запрос с температурой = 0, 0.7 и 1.2
### - Сравните результаты (точность, креативность, разнообразие)
### - Сформулируйте, для каких задач лучше подходит каждая настройка

- `Результат`: Текст или код с примерами разных ответов
- `Формат`: Видео + Код

[Видео результата](https://drive.google.com/file/d/1Ez8kYKJp6GiEKtGZFZ5YzxXAltl-M2fJ/view?usp=sharing)
### Вывод
Параметр temperature в API к lmm отвечает за "степень случайности" при генерации текста модели, то есть насколько креативными и непредсказуемыми будут ответы.
Как работает temperature
- При низких значениях (например, 0–0.3) модель выбирает самые вероятные варианты слов, ответы получаются более строгими, фактическими и одинаковыми при повторных запросах.
- При средних значениях (0.4–0.7) появляется баланс между предсказуемостью и вариативностью – это удобно для большинства задач, где нужна и точность, и немного креатива.
- При высоких значениях (1.0 и выше, до 2.0) модель сильнее "экспериментирует", чаще выбирает менее вероятные токены, поэтому текст становится более разнообразным и творческим, но может терять связанность.
