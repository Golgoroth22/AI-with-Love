# Fully Local RAG Architecture - Day 21

## Overview

The app now implements a **fully local** RAG (Retrieval-Augmented Generation) system:

- âœ… **Local text chunking** - Android app
- âœ… **Local embedding generation** - Local Ollama on your machine
- âœ… **Local database storage** - SQLite in Android app
- âœ… **Local semantic search** - Cosine similarity in Android app
- ğŸŒ **Remote AI** - Only Perplexity API for chat responses

## Complete Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Android App                          â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Document Processing (OllamaViewModel)             â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  1. Read file (PDF/TXT/MD)                         â”‚ â”‚
â”‚  â”‚  2. Chunk text (TextChunker)                       â”‚ â”‚
â”‚  â”‚  3. Generate embeddings â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚ â”‚
â”‚  â”‚  4. Save to LOCAL database      â”‚                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                    â”‚                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Chat & Search (ChatViewModel)  â”‚                  â”‚ â”‚
â”‚  â”‚                                 â”‚                  â”‚ â”‚
â”‚  â”‚  1. User question               â”‚                  â”‚ â”‚
â”‚  â”‚  2. Generate query embedding â”€â”€â”€â”¤                  â”‚ â”‚
â”‚  â”‚  3. Search LOCAL database       â”‚                  â”‚ â”‚
â”‚  â”‚  4. Format results              â”‚                  â”‚ â”‚
â”‚  â”‚  5. Send to Perplexity â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚     â”‚ â”‚
â”‚                                                  â”‚     â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚     â”‚ â”‚
â”‚  â”‚  Local SQLite Database          â”‚            â”‚     â”‚ â”‚
â”‚  â”‚  (EmbeddingsDatabase)           â”‚            â”‚     â”‚ â”‚
â”‚  â”‚                                 â”‚            â”‚     â”‚ â”‚
â”‚  â”‚  - Document chunks              â”‚            â”‚     â”‚ â”‚
â”‚  â”‚  - 768-dim embeddings           â”‚            â”‚     â”‚ â”‚
â”‚  â”‚  - Source metadata              â”‚            â”‚     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚     â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”
                â”‚  Local Ollama                    â”‚     â”‚
                â”‚  (Your Machine)                  â”‚     â”‚
                â”‚                                  â”‚     â”‚
                â”‚  Model: nomic-embed-text         â”‚     â”‚
                â”‚  Dimensions: 768                 â”‚     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                                                         â”‚
                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”
                                      â”‚  Perplexity API     â”‚
                                      â”‚  (Remote)           â”‚
                                      â”‚                     â”‚
                                      â”‚  - Chat completion  â”‚
                                      â”‚  - Agentic tools    â”‚
                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Key Components

### 1. Local Database (EmbeddingsDatabase)

**Location**: `app/src/main/java/com/example/aiwithlove/database/`

**Files**:
- `EmbeddingsDatabase.kt` - Room database definition
- `DocumentChunkEntity.kt` - Chunk storage model
- `DocumentChunkDao.kt` - Database access interface
- `EmbeddingsRepository.kt` - Business logic layer

**Schema**:
```kotlin
@Entity(tableName = "document_chunks")
data class DocumentChunkEntity(
    @PrimaryKey(autoGenerate = true)
    val id: Long = 0,
    val content: String,
    val embedding: List<Double>,  // 768 dimensions
    val sourceFile: String,
    val sourceType: String,
    val chunkIndex: Int,
    val totalChunks: Int,
    val createdAt: Long
)
```

**Storage**: SQLite database file in app's private storage (`/data/data/com.example.aiwithlove/databases/embeddings_database`)

### 2. Embeddings Repository

**Purpose**: Manage document chunks and perform semantic search

**Key Methods**:

```kotlin
// Save chunk with embedding
suspend fun saveChunk(
    content: String,
    embedding: List<Double>,
    sourceFile: String,
    sourceType: String,
    chunkIndex: Int,
    totalChunks: Int
): Long

// Semantic search with cosine similarity
suspend fun searchSimilar(
    queryEmbedding: List<Double>,
    limit: Int = 5,
    threshold: Double = 0.6
): List<SimilarChunk>

// Get total chunks count
suspend fun getChunksCount(): Int
```

**Cosine Similarity Calculation**:
```kotlin
private fun cosineSimilarity(vec1: List<Double>, vec2: List<Double>): Double {
    val dotProduct = vec1.zip(vec2).sumOf { it.first * it.second }
    val magnitude1 = sqrt(vec1.sumOf { it * it })
    val magnitude2 = sqrt(vec2.sumOf { it * it })
    return dotProduct / (magnitude1 * magnitude2)
}
```

### 3. Document Processing Flow

**OllamaViewModel** handles document upload:

```kotlin
fun uploadDocument(uri: Uri, fileName: String, context: Context) {
    // 1. Read file
    val text = readFile(uri)

    // 2. Chunk locally
    val chunks = TextChunker.chunkTextWithMetadata(text)

    // 3. For each chunk:
    for (chunk in chunks) {
        // Generate embedding with LOCAL Ollama
        val embedding = ollamaClient.generateEmbedding(chunk.content)

        // Save to LOCAL database
        embeddingsRepository.saveChunk(
            content = chunk.content,
            embedding = embedding,
            sourceFile = fileName,
            sourceType = sourceType,
            chunkIndex = chunk.chunkIndex,
            totalChunks = chunks.size
        )
    }
}
```

### 4. Semantic Search Flow

**ChatViewModel** handles semantic search:

```kotlin
// User asks: "Ğ½Ğ°Ğ¹Ğ´Ğ¸ Ğ² Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ… Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ"

// 1. Generate query embedding
val queryEmbedding = ollamaClient.generateEmbedding(userQuery)

// 2. Search in LOCAL database
val results = embeddingsRepository.searchSimilar(
    queryEmbedding = queryEmbedding,
    limit = 5,
    threshold = 0.6
)

// 3. Format results and send to Perplexity
val context = results.map { it.chunk.content }.joinToString("\n\n")
perplexityService.sendAgenticRequest(
    userMessage = userQuery,
    context = context
)
```

## Data Flow Examples

### Example 1: Upload Document

```
User selects CLAUDE.md
         â†“
OllamaViewModel.uploadMarkdownFile()
         â†“
Read file: 15,635 characters
         â†“
TextChunker.chunkTextWithMetadata()
         â†“
16 chunks created
         â†“
For each chunk:
    OllamaClient.generateEmbedding()
         â†“
    HTTP POST â†’ http://10.0.2.2:11434/api/embeddings
         â†“
    Response: [768 doubles]
         â†“
    EmbeddingsRepository.saveChunk()
         â†“
    SQLite INSERT INTO document_chunks
         â†“
Result: 16 chunks saved to LOCAL database
```

### Example 2: Semantic Search

```
User asks: "Ğ½Ğ°Ğ¹Ğ´Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ"
         â†“
ChatViewModel.executeAgenticToolCall("semantic_search")
         â†“
OllamaClient.generateEmbedding(query)
         â†“
HTTP POST â†’ http://10.0.2.2:11434/api/embeddings
         â†“
Query embedding: [768 doubles]
         â†“
EmbeddingsRepository.searchSimilar()
         â†“
SELECT * FROM document_chunks
         â†“
For each chunk:
    cosineSimilarity(queryEmbedding, chunkEmbedding)
         â†“
Filter by threshold (0.6)
         â†“
Sort by similarity DESC
         â†“
Take top 5
         â†“
Result: 5 most relevant chunks
         â†“
Send to Perplexity with context
```

## Performance Characteristics

### Storage

| Data | Size |
|------|------|
| 1 chunk content | ~1 KB (1000 chars) |
| 1 embedding | ~6 KB (768 doubles Ã— 8 bytes) |
| **Total per chunk** | **~7 KB** |
| 100 chunks (small doc) | ~700 KB |
| 1000 chunks (large doc) | ~7 MB |

### Processing Speed

| Operation | Time |
|-----------|------|
| Read file (15 KB) | < 1 second |
| Chunk text (16 chunks) | < 1 second |
| Generate 1 embedding | ~1-2 seconds |
| Generate 16 embeddings | ~20-30 seconds |
| Save 1 chunk to DB | ~10 ms |
| **Total for 15 KB file** | **~25-35 seconds** |

### Search Speed

| Operation | Time |
|-----------|------|
| Generate query embedding | ~1-2 seconds |
| Search 100 chunks | < 100 ms |
| Search 1000 chunks | ~500 ms |
| Search 10000 chunks | ~5 seconds |
| **Total search** | **~1-7 seconds** |

## Advantages of Local Architecture

### 1. Privacy âœ…
- **No data leaves device** except for:
  - AI chat requests to Perplexity (necessary for responses)
- All document content stays on device
- All embeddings generated and stored locally

### 2. Speed âš¡
- **No network latency** for embeddings and search
- Embedding generation: limited by Ollama performance
- Search: instant (< 1 second for 1000 chunks)

### 3. Offline Capability ğŸ“´
- **Works without internet** for:
  - Document indexing
  - Semantic search
- Only needs internet for:
  - AI chat responses (Perplexity API)

### 4. Cost ğŸ’°
- **No server costs** for:
  - Embedding generation (uses your GPU/CPU)
  - Database storage (free on device)
  - Search operations (local computation)
- Only cost:
  - Perplexity API calls (~$0.001/request)

### 5. Scalability ğŸ“ˆ
- **Limited by device storage**:
  - 1 GB storage = ~140,000 chunks
  - Enough for 140 MB of text
- Search scales linearly with chunk count
- Can handle 10,000 chunks with acceptable performance

## Disadvantages & Trade-offs

### 1. Device Requirements
- **Requires local Ollama**:
  - Must run on development machine
  - Emulator can't run Ollama itself
- **Storage**: Documents stored on device (uses app storage)
- **Processing**: Embedding generation uses local CPU/GPU

### 2. Synchronization
- **No cloud sync**: Documents only on one device
- **No sharing**: Can't share indexed documents between users
- **No backup**: Documents lost if app data cleared

### 3. Performance Limits
- **Embedding speed**: ~1-2 seconds per chunk
  - Slower on CPU-only machines
  - Faster with GPU acceleration
- **Search speed**: Linear with chunk count
  - 10,000 chunks = ~5 seconds
  - Consider pagination/filtering for large databases

## Configuration

### OllamaClient Settings

```kotlin
// ServerConfig.kt
const val OLLAMA_API_URL = "http://10.0.2.2:11434"  // Emulator
// const val OLLAMA_API_URL = "http://192.168.1.100:11434"  // Physical device
```

### Database Settings

```kotlin
// Room configuration
Room.databaseBuilder(
    context.applicationContext,
    EmbeddingsDatabase::class.java,
    "embeddings_database"  // Database file name
)
    .fallbackToDestructiveMigration()  // Drop and recreate on schema change
    .build()
```

### Chunking Settings

```kotlin
// TextChunker configuration
fun chunkText(
    text: String,
    chunkSize: Int = 1000,      // Characters per chunk
    chunkOverlap: Int = 200     // Overlap between chunks
): List<String>
```

### Search Settings

```kotlin
// EmbeddingsRepository configuration
suspend fun searchSimilar(
    queryEmbedding: List<Double>,
    limit: Int = 5,              // Max results
    threshold: Double = 0.6      // Min similarity (0.0-1.0)
): List<SimilarChunk>
```

## Usage Examples

### Upload Document

```kotlin
// In your app
val viewModel: OllamaViewModel by viewModel()

// User selects file
viewModel.uploadDocument(
    uri = fileUri,
    fileName = "document.pdf",
    context = applicationContext
)

// Progress updates via StateFlow
viewModel.documentUploadState.collect { state ->
    when (state) {
        is DocumentUploadState.Reading -> show("Reading file...")
        is DocumentUploadState.Uploading -> show(state.progress)
        is DocumentUploadState.Success -> show("Done! ${state.chunksCount} chunks")
        is DocumentUploadState.Error -> show("Error: ${state.message}")
    }
}
```

### Semantic Search

```kotlin
// In ChatViewModel (automatic when user asks question)
val query = "Ğ½Ğ°Ğ¹Ğ´Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ"

// Generate query embedding
val queryEmbedding = ollamaClient.generateEmbedding(query)

// Search local database
val results = embeddingsRepository.searchSimilar(
    queryEmbedding = queryEmbedding,
    limit = 5,
    threshold = 0.6
)

// Use results
results.forEach { result ->
    println("Similarity: ${result.similarity}")
    println("Content: ${result.chunk.content}")
    println("Source: ${result.chunk.sourceFile}")
}
```

### Database Management

```kotlin
// Get statistics
val totalChunks = embeddingsRepository.getChunksCount()
val fileNames = embeddingsRepository.getAllFileNames()

// Get chunks by file
val chunks = embeddingsRepository.getChunksByFile("CLAUDE.md")

// Delete file's chunks
embeddingsRepository.deleteChunksByFile("CLAUDE.md")

// Clear all data
embeddingsRepository.deleteAllChunks()
```

## Testing

### 1. Test Document Upload

```kotlin
// Run app
// Navigate to Ollama screen
// Upload CLAUDE.md
// Expected: ~16 chunks saved in ~30 seconds
// Check database: should have 16 rows
```

### 2. Test Semantic Search

```kotlin
// Navigate to Chat screen
// Ask: "Ğ½Ğ°Ğ¹Ğ´Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğµ"
// Expected: AI finds relevant chunks from LOCAL database
// Response includes citations from local documents
```

### 3. Check Database

```bash
# Access database via adb
adb shell
run-as com.example.aiwithlove
cd databases
sqlite3 embeddings_database

# Check data
SELECT COUNT(*) FROM document_chunks;
SELECT sourceFile, COUNT(*) FROM document_chunks GROUP BY sourceFile;
SELECT id, substr(content, 1, 50), similarity FROM document_chunks LIMIT 5;
```

## Future Enhancements

### 1. Vector Indexing
- **Problem**: Linear search (O(n)) slow for large databases
- **Solution**: Implement approximate nearest neighbor (ANN) indexing
  - HNSW (Hierarchical Navigable Small World) graphs
  - Can reduce search time from O(n) to O(log n)

### 2. Batch Processing
- **Problem**: Sequential embedding generation is slow
- **Solution**: Batch embeddings
  - Send multiple chunks to Ollama in one request
  - Requires Ollama API support for batch embeddings

### 3. Background Sync
- **Problem**: Documents only on one device
- **Solution**: Optional cloud backup
  - Encrypt embeddings before upload
  - Sync between devices
  - Share documents with other users

### 4. Compression
- **Problem**: Embeddings take ~6 KB each
- **Solution**: Quantization
  - Float64 â†’ Float32: 50% size reduction
  - Float32 â†’ Int8: 75% size reduction
  - Minimal accuracy loss

### 5. Hybrid Search
- **Problem**: Semantic search misses exact matches
- **Solution**: Combine with full-text search
  - SQLite FTS5 for keyword search
  - Combine scores: `final_score = 0.7 * semantic + 0.3 * keyword`

## Troubleshooting

### Database Issues

**Problem**: Database corrupted or schema mismatch

**Solution**:
```kotlin
// Clear app data
Settings â†’ Apps â†’ AI with Love â†’ Storage â†’ Clear Data

// Or rebuild database
Room.databaseBuilder(...)
    .fallbackToDestructiveMigration()
    .build()
```

### Slow Search

**Problem**: Search takes > 5 seconds

**Possible causes**:
1. Too many chunks (> 10,000)
2. Complex similarity calculation
3. Unindexed database

**Solutions**:
```kotlin
// Add limit to chunks fetched
val chunks = dao.getChunksForSearch(limit = 1000)

// Consider pagination
suspend fun searchSimilar(
    queryEmbedding: List<Double>,
    limit: Int = 5,
    offset: Int = 0  // Add pagination
): List<SimilarChunk>
```

### Ollama Connection Issues

**Problem**: Can't generate embeddings

**Solutions**:
See `QUICKSTART.md` for Ollama setup and troubleshooting

## Summary

The app now implements a **fully local RAG system**:

âœ… All document processing happens locally
âœ… All embeddings stored locally (SQLite)
âœ… All searches run locally (cosine similarity)
âœ… Only AI responses use remote API (Perplexity)

**Benefits**: Privacy, speed, offline capability, no server costs
**Trade-offs**: Device requirements, no sync, linear search scaling

This architecture is ideal for:
- Personal knowledge management
- Privacy-sensitive applications
- Offline-first workflows
- Development and testing
