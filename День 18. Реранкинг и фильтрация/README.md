# День 18. Реранкинг и фильтрация

1. Добавьте второй этап после поиска: reranker или фильтр релевантности (например, через порог коэффициента похожести или используя стороннюю модель)
2. Сравните качество ответа без фильтра и с фильтром
3. Настройте порог отсечения нерелевантных результатов

- `Результат`: Улучшенный RAG с фильтрацией/реранкингом
- `Формат`: Видео + Код

[Видео результата](https://drive.google.com/file/d/1MGLxyJEWFCbdA3TY7JT6UU5t00mk878H/view?usp=sharing)

Код mcp-сервера в директории **server/**

1. Экран с аи-ассистентом с возможностью использования mcp-сервера. У mcp-сервера 5 tools:
- get_joke - Получить случайную шутку из JokeAPI.
- save_joke - Сохранить шутку в локальную датабазу на сервере.
- get_saved_jokes - Достать все шутки из локальной датабазы на сервере.
- run_tests - Запуск тестов MCP сервера в изолированном Docker контейнере. Выполняет все модульные тесты и возвращает результаты.
- semantic_search - Поиск релевантных чанков из индексированных документов, используя семантическое сходство. 
2. Экран для работы с ollama на mcp-сервере. Можно как закинуть текст руками, так и файлы целиком. Чанки лежат в базе данных на сервере. Трещхолд фильтр реализован мануальный на стороне сервера @http_mcp_server.py

Вывод:
Без фильтра — LLM получает все найденные чанки, включая слаборелевантные, что повышает риск галлюцинаций и снижает точность ответов. С фильтром — в контекст попадают только чанки с высокой степенью схожести, что делает ответы более точными. Фильтр особенно эффективен в узкоспециализированных областях, где критически важна фактологическая точность.